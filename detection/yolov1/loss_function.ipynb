{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "from dataloader import CustomImageDataset, DataLoader\n",
    "from torchvision.transforms import Compose\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = Compose([\n",
    "    transforms.ToTensor(), # Scales data into [0,1]\n",
    "    transforms.Lambda(lambda t: (t * 2) - 1) # Scale between [-1, 1]\n",
    "])\n",
    "\n",
    "dataset = CustomImageDataset(annotations_dir = '/home/pqbas/dl/detection/MNIST-ObjectDetection/data/mnist_detection/test/labels',\n",
    "                             img_dir = '/home/pqbas/dl/detection/MNIST-ObjectDetection/data/mnist_detection/test/images',\n",
    "                             data_transform = transform,\n",
    "                             size=(448,448))\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "\n",
    "def clean_gpu():\n",
    "    for i in range(10):    \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at 0/10 is: 138.23953961569165\n",
      "Loss at 1/10 is: 127.59218500530909\n",
      "Loss at 2/10 is: 124.0501427827058\n",
      "Loss at 3/10 is: 122.26870162903316\n",
      "Loss at 4/10 is: 121.1739147004627\n",
      "Loss at 5/10 is: 120.44005097283258\n",
      "Loss at 6/10 is: 119.91102423635469\n",
      "Loss at 7/10 is: 119.52486708807567\n",
      "Loss at 8/10 is: 119.21416638894055\n",
      "Loss at 9/10 is: 118.98168389456613\n"
     ]
    }
   ],
   "source": [
    "from model import YOLOv1\n",
    "import torchvision.transforms as T\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# to plot the loss\n",
    "loss_history = []\n",
    "\n",
    "# clean gpu before wathever\n",
    "clean_gpu()\n",
    "\n",
    "# model\n",
    "model = YOLOv1(S=7, depth=1).to(device)\n",
    "model.train()\n",
    "\n",
    "# optimizatino algorithm\n",
    "mse = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "#training loop\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    n_break = 0\n",
    "    for idx, data in enumerate(train_loader):\n",
    "        # get the inputs\n",
    "        img, target = data\n",
    "        img, target = img.to(device), target['one_obj'].to(device)\n",
    "\n",
    "        # zero the parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward\n",
    "        prediction = model(img)\n",
    "        predict_confidence = torch.sigmoid(prediction[...,0])\n",
    "        target_confidence = target.squeeze()\n",
    "\n",
    "        # backward + optimize\n",
    "        loss = mse(target_confidence, predict_confidence)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        loss_history.append(loss.detach().item())\n",
    "\n",
    "        # if idx == n_break:\n",
    "        #     break\n",
    "\n",
    "    print(f'Loss at {epoch}/{EPOCHS} is: {np.average(np.array(loss_history))}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    img = (img + 1)/2\n",
    "    img_ = T.ToPILImage()(img[0])\n",
    "\n",
    "    w = pred_box1[0,:,:,2]*448\n",
    "    h = pred_box1[0,:,:,2]*448\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'one_obj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m n_break \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx,(img, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m---> 13\u001b[0m     one_obj \u001b[38;5;241m=\u001b[39m \u001b[43mone_obj\u001b[49m[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m     15\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m model(img)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# ========================== #\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#        Object Loss         #\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# ========================== #\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'one_obj' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from metrics import intersection_over_union\n",
    "from model import YOLOv1\n",
    "\n",
    "model = YOLOv1(B=2, C=10, S=7)\n",
    "\n",
    "mse = nn.MSELoss(reduction='sum')\n",
    "\n",
    "n_break = 0\n",
    "for idx,(img, target) in enumerate(train_loader):\n",
    "    \n",
    "    one_obj = one_obj[...,0][...,None]\n",
    "    \n",
    "    prediction = model(img)\n",
    "\n",
    "    # ========================== #\n",
    "    #        Object Loss         #\n",
    "    # ========================== #\n",
    "\n",
    "    target_box = target[...,0:4]\n",
    "\n",
    "    box1 = torch.sigmoid(prediction[...,0:4])\n",
    "    box2 = torch.sigmoid(prediction[...,4:8])\n",
    "\n",
    "    iou1 = intersection_over_union(box1, target_box)\n",
    "    iou2 = intersection_over_union(box2, target_box)\n",
    "    \n",
    "    ious = torch.cat([iou1,iou2], dim=3)\n",
    "    max, bestbox = torch.max(ious, dim=3)\n",
    "    \n",
    "    box = (bestbox[...,None]*box2 +  (1 - bestbox[...,None])*box1) * one_obj\n",
    "\n",
    "    box[...,2:4] = torch.sqrt(box[...,2:4])\n",
    "    target[...,2:4] = torch.sqrt(target_box[...,2:4])\n",
    "\n",
    "    box_coordinates_loss = mse(box,target_box)\n",
    "    \n",
    "    # ========================== #\n",
    "    #        Classf Loss         #\n",
    "    # ========================== #\n",
    "\n",
    "    pred_prob = prediction[...,10:21]*one_obj\n",
    "    target_prob = target[...,4:15]*one_obj\n",
    "\n",
    "    classf_loss = mse(pred_prob, target_prob)\n",
    "\n",
    "\n",
    "    # ========================= #\n",
    "    #        Noobj Loss         #\n",
    "    # ========================= #\n",
    "\n",
    "    noobj = 1 - one_obj\n",
    "    noobj_pred_prob = prediction[...,10:21]*noobj\n",
    "    noobj_target_prob = target[...,4:15]*noobj\n",
    "\n",
    "    print(noobj_pred_prob.shape)\n",
    "    print(noobj_target_prob.shape)\n",
    "\n",
    "    mse(noobj_pred_prob, noobj_target_prob)\n",
    "\n",
    "\n",
    "    if idx == n_break:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from metrics import intersection_over_union\n",
    "from model import YOLOv1\n",
    "\n",
    "model = YOLOv1(B=2, C=10, S=7)\n",
    "\n",
    "n_break = 0\n",
    "for idx,(img, target) in enumerate(train_loader):\n",
    "    \n",
    "    one_obj = one_obj[...,0][...,None]\n",
    "    \n",
    "    prediction = model(img)\n",
    "\n",
    "    target['']\n",
    "\n",
    "    mse(noobj_pred_prob, noobj_target_prob)\n",
    "\n",
    "\n",
    "    if idx == n_break:\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
